# -*- coding: utf-8 -*-
"""nlp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yZEVsHFKs_aHXtNeB6TEUtNKCyQn4iOA
"""

# Task(a): Reading data from file
f = open('nlp_input.txt', 'rb')
input = f.read()

# Task(b): Tokenize the text into words
from nltk.tokenize import sent_tokenize, word_tokenize
input = input.decode('latin-1')      
print(sent_tokenize(input))

wordTokens = word_tokenize(input)
print(wordTokens)

# Task(b): Apply lemmatization technique on each word.
from nltk.stem import WordNetLemmatizer
nltk.download('wordnet')
lemmatizer = WordNetLemmatizer()

for wordTokens in wordTokens:
    print(lemmatizer.lemmatize(wordTokens))
print("\n")

# Task(c): Trigram
triDic = {}
count =1
trigrams = nltk.trigrams(input.split())
print("----Task(c): Trigram\n")

for trigram in trigrams:
    dicKey=' '.join(trigram)
    # print(dicKey)
    if dicKey in triDic.keys():
        triDic.update({dicKey:triDic[dicKey]+1})
    else:
        triDic[dicKey]=1
print(triDic,"\n")

#Task(d) to get top 10 values from dictionary
from heapq import nlargest

TenHighest = nlargest(10, triDic, key=triDic.get)

print("----Task(d):Dictionary with 10 highest values:")

for val in TenHighest:
    print(val, ":", triDic.get(val))
print("\n")

#Task(e & f ): Tokenizing into sentence and Find all the sentences with the most repeated tri-grams
# Task (g & h): Extract those sentences and concatenate and print the concatenated result

sentTokens = nltk.sent_tokenize(input)
maxValue = max(triDic, key=triDic.get)
concatenatedString=''
print("Task(e,f) Combined")
print("----All the sentences with the most repeated tri-grams----\n")

for stoken in sentTokens:
    if maxValue in stoken:
       print(stoken)
       concatenatedString = concatenatedString+stoken
print("\n")
print("Task(g,h) Combined")
print("----Concatenated Result----\n")
print(concatenatedString)